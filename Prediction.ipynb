{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Install Dependencies & Mount Google Drive**"
      ],
      "metadata": {
        "id": "RG02wtwB98IK"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jQHh_WnB9qui",
        "outputId": "0321ef04-0bff-4830-c67d-515f3693f581"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "from google.colab import drive\n",
        "\n",
        "#  Mount Google Drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Configuration**"
      ],
      "metadata": {
        "id": "VbjGS_jh-SHC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "MODEL_NAME = \"unet\"  # Ensure this matches the trained model name\n",
        "SAVE_MODEL_PATH = \"/content/drive/MyDrive/Medical_Image_Segmentation_Pipeline/save_trained_models\"  # Folder where trained models are saved\n",
        "INPUT_IMAGE_PATH = \"/content/drive/MyDrive/Medical_Image_Segmentation_Pipeline/input_images\"  # Folder containing images for prediction\n",
        "PREDICTED_MASK_PATH = \"/content/drive/MyDrive/Medical_Image_Segmentation_Pipeline/predicted_masks\"  # Folder where masks will be saved\n",
        "IMG_SIZE = 256\n",
        "# Ensure the predicted masks folder exists\n",
        "os.makedirs(PREDICTED_MASK_PATH, exist_ok=True)"
      ],
      "metadata": {
        "id": "bRxA1RN8-RHJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Load Trained Model**"
      ],
      "metadata": {
        "id": "f6T4eweT_JaN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# Re-define dice loss (needed for loading the model)\n",
        "def dice_coefficient(y_true, y_pred, smooth=1):\n",
        "    y_true_f = tf.keras.backend.flatten(y_true)\n",
        "    y_pred_f = tf.keras.backend.flatten(y_pred)\n",
        "    intersection = tf.keras.backend.sum(y_true_f * y_pred_f)\n",
        "    return (2. * intersection + smooth) / (tf.keras.backend.sum(y_true_f) + tf.keras.backend.sum(y_pred_f) + smooth)\n",
        "\n",
        "def dice_loss(y_true, y_pred, smooth=1):\n",
        "    y_true_f = tf.keras.backend.flatten(y_true)\n",
        "    y_pred_f = tf.keras.backend.flatten(y_pred)\n",
        "    intersection = tf.keras.backend.sum(y_true_f * y_pred_f)\n",
        "    return 1-(2. * intersection + smooth) / (tf.keras.backend.sum(y_true_f) + tf.keras.backend.sum(y_pred_f) + smooth)\n",
        "\n",
        "model_path = os.path.join(SAVE_MODEL_PATH, f\"{MODEL_NAME}_trained.h5\")\n",
        "# Load model with custom loss function\n",
        "model = tf.keras.models.load_model(model_path, custom_objects={\"dice_loss\": dice_loss})\n",
        "\n",
        "print(f\"Model '{MODEL_NAME}' loaded successfully!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hUtKLZjw_GMG",
        "outputId": "22e6b6e3-7c5b-46ec-acd0-c36666d42558"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model 'unet' loaded successfully!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Load Input Images**"
      ],
      "metadata": {
        "id": "ghYmOQ2--t40"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input_images = sorted(os.listdir(INPUT_IMAGE_PATH))\n",
        "if not input_images:\n",
        "    raise FileNotFoundError(f\"No input images found in {INPUT_IMAGE_PATH}\")\n",
        "\n",
        "print(f\"Found {len(input_images)} input images for prediction.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UpOGDl0o-7NO",
        "outputId": "db329f1a-9e18-4038-a222-1ab049712c0e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 2 input images for prediction.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Function to Load & Preprocess Image**"
      ],
      "metadata": {
        "id": "rmrV81RH_Rvd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def load_and_preprocess_image(image_path):\n",
        "    \"\"\"Load and preprocess image for model prediction.\"\"\"\n",
        "    image = cv2.imread(image_path)  # Load with OpenCV (to preserve original size)\n",
        "    if image is None:\n",
        "        raise FileNotFoundError(f\"Image not found: {image_path}\")\n",
        "    # Save original size\n",
        "    orig_height, orig_width = image.shape[:2]\n",
        "    # Resize for model input using IMG_SIZE variable and normalize pixel values\n",
        "    image_resized = cv2.resize(image, (IMG_SIZE, IMG_SIZE))\n",
        "    image_resized = image_resized / 255.0\n",
        "    return image_resized, orig_height, orig_width\n"
      ],
      "metadata": {
        "id": "qCAX4gQV_ZuX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Predict & Save Masks**"
      ],
      "metadata": {
        "id": "fX8Q01t-_nTi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for img_name in input_images:\n",
        "    img_path = os.path.join(INPUT_IMAGE_PATH, img_name)\n",
        "\n",
        "    # Load & preprocess image using updated function\n",
        "    image, orig_height, orig_width = load_and_preprocess_image(img_path)\n",
        "    image_input = np.expand_dims(image, axis=0)  # Add batch dimension\n",
        "\n",
        "    # Predict mask using the model\n",
        "    predicted_mask = model.predict(image_input)[0]\n",
        "    # Convert prediction to binary mask using threshold 0.5\n",
        "    binary_mask = (predicted_mask > 0.9).astype(np.uint8) * 255\n",
        "\n",
        "    # Resize mask back to original image size using nearest-neighbor interpolation\n",
        "    predicted_mask_resized = cv2.resize(binary_mask, (orig_width, orig_height), interpolation=cv2.INTER_NEAREST)\n",
        "\n",
        "    # Save predicted mask (saving part kept unchanged)\n",
        "    mask_save_path = os.path.join(PREDICTED_MASK_PATH, img_name)\n",
        "    cv2.imwrite(mask_save_path, predicted_mask_resized)\n",
        "\n",
        "    print(f\"Saved predicted mask: {mask_save_path}\")\n",
        "\n",
        "print(\"🎉 *Prediction Complete! Masks saved successfully.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1K9TbZZr_xjT",
        "outputId": "311f981d-e7d1-4354-a71b-11113e6eb96a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 532ms/step\n",
            "Saved predicted mask: /content/drive/MyDrive/Medical_Image_Segmentation_Pipeline/predicted_masks/b.jpg\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 251ms/step\n",
            "Saved predicted mask: /content/drive/MyDrive/Medical_Image_Segmentation_Pipeline/predicted_masks/c.jpg\n",
            "🎉 *Prediction Complete! Masks saved successfully.\n"
          ]
        }
      ]
    }
  ]
}